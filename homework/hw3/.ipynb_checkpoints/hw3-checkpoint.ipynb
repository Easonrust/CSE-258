{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks(Cook/Make prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s split the training data (‘trainInteractions.csv.gz’) as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Reviews 1-400,000 for training \\\n",
    "(2) Reviews 400,000-500,000 for validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Evaluate the performance (accuracy) of the baseline model on the validation set you have built "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import random\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"assignment1/trainInteractions.csv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    c = csv.reader(f)\n",
    "    header = next(c)\n",
    "    for l in c:\n",
    "        d = dict(zip(header,l))\n",
    "        yield d['user_id'],d['recipe_id'],d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_validate_set(dataset):\n",
    "    validate_set=[]\n",
    "    random.seed(50)\n",
    "    for d in dataset:\n",
    "        positive_entry=[d[0],d[1],1]\n",
    "        negative_entry_item_set=itemSet.difference(itemsPerUser[d[0]])\n",
    "        random_item=random.choice(list(negative_entry_item_set))\n",
    "        negative_entry=[d[0],random_item,0]\n",
    "        validate_set.append(positive_entry)\n",
    "        validate_set.append(negative_entry)\n",
    "    return validate_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train_set(dataset):\n",
    "    train_set=[]\n",
    "    for d in dataset:\n",
    "        positive_entry=[d[0],d[1]]\n",
    "        train_set.append(positive_entry)\n",
    "    return train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = list(readCSV(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('88348277',\n",
       " '03969194',\n",
       " {'user_id': '88348277',\n",
       "  'recipe_id': '03969194',\n",
       "  'date': '2004-12-23',\n",
       "  'rating': '5'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemsPerUser = defaultdict(set)\n",
    "usersPerItem=defaultdict(set)\n",
    "itemSet=set([d[1] for d in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dataset:\n",
    "    user,item = d[0], d[1]\n",
    "    itemsPerUser[user].add(item)\n",
    "    usersPerItem[item].add(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set=build_train_set(dataset[:400000])\n",
    "validate_set=build_validate_set(dataset[400000:500000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['88348277', '03969194'],\n",
       " ['86699739', '27096427'],\n",
       " ['03425965', '44197323'],\n",
       " ['73973193', '24971400'],\n",
       " ['15215209', '60170202'],\n",
       " ['75799794', '39662395'],\n",
       " ['77745222', '88709727'],\n",
       " ['80598779', '09359141'],\n",
       " ['35769308', '83909791'],\n",
       " ['31763244', '20530585']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['90764166', '01768679', 1],\n",
       " ['90764166', '10493396', 0],\n",
       " ['68112239', '24923981', 1],\n",
       " ['68112239', '02378326', 0],\n",
       " ['32173358', '57597698', 1],\n",
       " ['32173358', '27114352', 0],\n",
       " ['30893740', '16266088', 1],\n",
       " ['30893740', '35819278', 0],\n",
       " ['69780905', '62953151', 1],\n",
       " ['69780905', '74035464', 0]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_set[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base line model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipeCount = defaultdict(int)\n",
    "totalCooked = 0\n",
    "\n",
    "# for user,recipe,_ in readCSV(\"assignment1/trainInteractions.csv.gz\"):\n",
    "#   recipeCount[recipe] += 1\n",
    "#   totalCooked += 1\n",
    "for d in train_set:\n",
    "  recipeCount[d[1]] += 1\n",
    "  totalCooked += 1\n",
    "\n",
    "mostPopular = [(recipeCount[x], x) for x in recipeCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "  count += ic\n",
    "  return1.add(i)\n",
    "  if count > totalCooked/2: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size=len(validate_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_size=0\n",
    "for i in range(total_size):\n",
    "    sample=validate_set[i]\n",
    "    item=sample[1]\n",
    "    predict=0\n",
    "    if item in return1:\n",
    "        predict=1\n",
    "    if predict==sample[2]:\n",
    "        correct_size+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67036"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy=correct_size/total_size\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. See if you can find a better threshold and report its performance on your validation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model_accuracy(threshhold):\n",
    "    return1 = set()\n",
    "    count = 0\n",
    "    for ic, i in mostPopular:\n",
    "      count += ic\n",
    "      return1.add(i)\n",
    "      if count > totalCooked*threshhold: break\n",
    "    correct_size=0\n",
    "    for i in range(total_size):\n",
    "        sample=validate_set[i]\n",
    "        item=sample[1]\n",
    "        predict=0\n",
    "        if item in return1:\n",
    "            predict=1\n",
    "        if predict==sample[2]:\n",
    "            correct_size+=1\n",
    "    accuracy=correct_size/total_size\n",
    "    print([accuracy,threshhold])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We go through 1/10 to 9/10 to check the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54719, 0.1]\n",
      "[0.590585, 0.2]\n",
      "[0.627285, 0.30000000000000004]\n",
      "[0.653845, 0.4]\n",
      "[0.67036, 0.5]\n",
      "[0.6761, 0.6000000000000001]\n",
      "[0.66722, 0.7000000000000001]\n",
      "[0.63698, 0.8]\n",
      "[0.557975, 0.9]\n",
      "[0.464665, 1.0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    baseline_model_accuracy((i+1)*0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that when threshhold is 3*totalCooked/5, the accuracy improve to 0.6761, so 3*totalCooked/5 is a better threshhold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. A stronger baseline than the one provided might make use of the Jaccard similarity (or another similarity\n",
    "metric). Given a pair (u,g) in the validation set, consider all training items g′ that user u has cooked. For each, compute the Jaccard similarity between g and g′, i.e., users (in the training set) who have made ′\n",
    "g and users who have made g . Predict as ‘made’ if the maximum of these Jaccard similarities exceeds a threshold (you may choose the threshold that works best). Report the performance on your validation set (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemsPerUser = defaultdict(set)\n",
    "usersPerItem=defaultdict(set)\n",
    "for d in train_set:\n",
    "    user,item = d[0], d[1]\n",
    "    itemsPerUser[user].add(item)\n",
    "    usersPerItem[item].add(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    if denom == 0:\n",
    "        return 0\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictUsingJaccard(item,user,t):\n",
    "    predict=0\n",
    "    maxSim=0\n",
    "    for d in itemsPerUser[user]:\n",
    "        sim=Jaccard(usersPerItem[d],usersPerItem[item])\n",
    "        maxSim=max(maxSim,sim)\n",
    "    if maxSim>t:\n",
    "        predict=1\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_model_accuracy(t):\n",
    "    total_size=len(validate_set)\n",
    "    correct_size=0\n",
    "    for i in range(total_size):\n",
    "        sample=validate_set[i]\n",
    "        item=sample[1]\n",
    "        user=sample[0]\n",
    "        predict=predictUsingJaccard(item,user,t)\n",
    "        if predict==sample[2]:\n",
    "            correct_size+=1\n",
    "    accuracy=correct_size/total_size\n",
    "    print([accuracy,t])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We go through t from 1/10 to 10/10 to check the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.500045, 0.1]\n",
      "[0.49333, 0.2]\n",
      "[0.49139, 0.30000000000000004]\n",
      "[0.494715, 0.4]\n",
      "[0.500095, 0.5]\n",
      "[0.50007, 0.6000000000000001]\n",
      "[0.5, 0.7000000000000001]\n",
      "[0.5, 0.8]\n",
      "[0.5, 0.9]\n",
      "[0.5, 1.0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    jaccard_model_accuracy((i+1)*0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we go through t from 1/100 to 1/10 to check the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.594055, 0.01]\n",
      "[0.584695, 0.02]\n",
      "[0.5612, 0.03]\n",
      "[0.53559, 0.04]\n",
      "[0.518795, 0.05]\n",
      "[0.510095, 0.06]\n",
      "[0.50591, 0.07]\n",
      "[0.502995, 0.08]\n",
      "[0.50182, 0.09]\n",
      "[0.500045, 0.1]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    jaccard_model_accuracy((i+1)*0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we go through t from 1/1000 to 1/100 to check the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58898, 0.001]\n",
      "[0.589675, 0.002]\n",
      "[0.591, 0.003]\n",
      "[0.59235, 0.004]\n",
      "[0.59303, 0.005]\n",
      "[0.593125, 0.006]\n",
      "[0.59335, 0.007]\n",
      "[0.594025, 0.008]\n",
      "[0.59398, 0.009000000000000001]\n",
      "[0.594055, 0.01]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    jaccard_model_accuracy((i+1)*0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we use 0.01 as our threshhold, and the accuracy on the validation set is 0.594055."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Improve the above predictor by incorporating both a Jaccard-based threshold and a popularity based threshold. Report the performance on your validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccardPopularityModel(train_set, test_set, jt=0.01, pt=0.6):\n",
    "    itemsPerUser = defaultdict(set)\n",
    "    usersPerItem=defaultdict(set)\n",
    "    for d in train_set:\n",
    "        user,item = d[0], d[1]\n",
    "        itemsPerUser[user].add(item)\n",
    "        usersPerItem[item].add(user)\n",
    "    \n",
    "    itemSet=set([d[1] for d in train_set])\n",
    "    userSet=set([d[0] for d in train_set])\n",
    "    \n",
    "    # calculate average number of recipes made in the train_set\n",
    "    averageNum=len(train_set)/len(userSet)\n",
    "\n",
    "    # calculate most popular set in train_set\n",
    "    recipeCount = defaultdict(int)\n",
    "    totalCooked = 0\n",
    "    for d in train_set:\n",
    "      recipeCount[d[1]] += 1\n",
    "      totalCooked += 1\n",
    "\n",
    "    mostPopular = [(recipeCount[x], x) for x in recipeCount]\n",
    "    mostPopular.sort()\n",
    "    mostPopular.reverse()\n",
    "\n",
    "    return1 = set()\n",
    "    count = 0\n",
    "    for ic, i in mostPopular:\n",
    "      count += ic\n",
    "      return1.add(i)\n",
    "      if count > totalCooked*pt: break\n",
    "\n",
    "    # evalute on test_set\n",
    "    total_size=len(test_set)\n",
    "    correct_size=0\n",
    "    for i in range(total_size):\n",
    "        sample=test_set[i]\n",
    "        item=sample[1]\n",
    "        user=sample[0]\n",
    "        predict=0\n",
    "        \n",
    "        # if we have not met this user before, just recommend the most popular\n",
    "        if user not in userSet:\n",
    "            if item in return1:\n",
    "                predict=1\n",
    "        else:\n",
    "            # if we have not met this recipe before, if the user made many recipes before, then recommend\n",
    "            if item not in itemSet:\n",
    "                if len(itemsPerUser[user])>averageNum:\n",
    "                    predict=1\n",
    "            else:     \n",
    "                maxSim=0\n",
    "                for d in itemsPerUser[user]:\n",
    "                    sim=Jaccard(usersPerItem[d],usersPerItem[item])\n",
    "                    maxSim=max(maxSim,sim)\n",
    "                if maxSim>jt and item in return1:\n",
    "                    predict=1\n",
    "                \n",
    "        if predict==sample[2]:\n",
    "            correct_size+=1\n",
    "    accuracy=correct_size/total_size\n",
    "    print([accuracy,jt,pt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.691455, 0.01, 0.6]\n"
     ]
    }
   ],
   "source": [
    "jaccardPopularityModel(train_set,validate_set,0.01,0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore the model incorporating Jaccard and popularity on validation set's accuracy is 0.691455."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. To run our model on the test set, we’ll have to use the files ‘stub Made.txt’ to find the user id/recipe id pairs about which we have to make predictions. Using that data, run the above model and upload your solution to Kaggle. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can change the popularity threshhold to see the outcome:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.684615, 0.01, 0.5]\n",
      "[0.685685, 0.01, 0.51]\n",
      "[0.686745, 0.01, 0.52]\n",
      "[0.68763, 0.01, 0.53]\n",
      "[0.688175, 0.01, 0.54]\n",
      "[0.688875, 0.01, 0.55]\n",
      "[0.689255, 0.01, 0.56]\n",
      "[0.689655, 0.01, 0.5700000000000001]\n",
      "[0.690655, 0.01, 0.58]\n",
      "[0.691285, 0.01, 0.59]\n",
      "[0.691455, 0.01, 0.6]\n",
      "[0.69139, 0.01, 0.61]\n",
      "[0.691215, 0.01, 0.62]\n",
      "[0.690815, 0.01, 0.63]\n",
      "[0.690635, 0.01, 0.64]\n",
      "[0.69077, 0.01, 0.65]\n",
      "[0.69071, 0.01, 0.66]\n",
      "[0.69065, 0.01, 0.67]\n",
      "[0.690305, 0.01, 0.6799999999999999]\n",
      "[0.690285, 0.01, 0.69]\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    jaccardPopularityModel(train_set,validate_set,0.01,0.50+i*0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore we still use 0.6 as our popularity threshhold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the popularity threshhold is more significant than similarity threshhold, so we modified our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccardPopularityModel(train_set, test_set, jt=0.01, pt=0.6):\n",
    "    itemsPerUser = defaultdict(set)\n",
    "    usersPerItem=defaultdict(set)\n",
    "    for d in train_set:\n",
    "        user,item = d[0], d[1]\n",
    "        itemsPerUser[user].add(item)\n",
    "        usersPerItem[item].add(user)\n",
    "    \n",
    "    itemSet=set([d[1] for d in train_set])\n",
    "    userSet=set([d[0] for d in train_set])\n",
    "    \n",
    "    # calculate average number of recipes made in the train_set\n",
    "    averageNum=len(train_set)/len(userSet)\n",
    "\n",
    "    # calculate most popular set in train_set\n",
    "    recipeCount = defaultdict(int)\n",
    "    totalCooked = 0\n",
    "    for d in train_set:\n",
    "        recipeCount[d[1]] += 1\n",
    "        totalCooked += 1\n",
    "\n",
    "    mostPopular = [(recipeCount[x], x) for x in recipeCount]\n",
    "    mostPopular.sort()\n",
    "    mostPopular.reverse()\n",
    "\n",
    "    return1 = set()\n",
    "    count = 0\n",
    "    for ic, i in mostPopular:\n",
    "        count += ic\n",
    "        return1.add(i)\n",
    "        if count > totalCooked*pt: break\n",
    "\n",
    "    # evalute on test_set\n",
    "    total_size=len(test_set)\n",
    "    correct_size=0\n",
    "    for i in range(total_size):\n",
    "        sample=test_set[i]\n",
    "        item=sample[1]\n",
    "        user=sample[0]\n",
    "        predict=0\n",
    "        \n",
    "        # if we have not met this user before, just recommend the most popular\n",
    "        if user not in userSet:\n",
    "            if item in return1:\n",
    "                predict=1\n",
    "        else:\n",
    "            # if we have not met this recipe before, if the user made many recipes before, then recommend\n",
    "            if item not in itemSet:\n",
    "                if len(itemsPerUser[user])>4/3*averageNum:\n",
    "                    predict=1\n",
    "            else:\n",
    "                if item in return1:\n",
    "                    predict=1\n",
    "                else:\n",
    "                    maxSim=0\n",
    "                    for d in itemsPerUser[user]:\n",
    "                        sim=Jaccard(usersPerItem[d],usersPerItem[item])\n",
    "                        maxSim=max(maxSim,sim)\n",
    "                    if maxSim>jt:\n",
    "                        predict=1\n",
    "                \n",
    "        if predict==sample[2]:\n",
    "            correct_size+=1\n",
    "    accuracy=correct_size/total_size\n",
    "    print([accuracy,jt,pt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-927c31873eb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjaccardPopularityModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidate_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-77-f1f5e7a92834>\u001b[0m in \u001b[0;36mjaccardPopularityModel\u001b[0;34m(train_set, test_set, jt, pt)\u001b[0m\n\u001b[1;32m     55\u001b[0m                     \u001b[0mmaxSim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitemsPerUser\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                         \u001b[0msim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mJaccard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musersPerItem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0musersPerItem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                         \u001b[0mmaxSim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxSim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmaxSim\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mjt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-84de7f90d817>\u001b[0m in \u001b[0;36mJaccard\u001b[0;34m(s1, s2)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mJaccard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mnumer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdenom\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "jaccardPopularityModel(train_set,validate_set,0.01,0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We modify it to upload the result to kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccardPopularityModel(train_set, jt=0.01, pt=0.6):\n",
    "    print(\"predicting....\")\n",
    "    itemsPerUser = defaultdict(set)\n",
    "    usersPerItem=defaultdict(set)\n",
    "    for d in train_set:\n",
    "        user,item = d[0], d[1]\n",
    "        itemsPerUser[user].add(item)\n",
    "        usersPerItem[item].add(user)\n",
    "    \n",
    "    itemSet=set([d[1] for d in train_set])\n",
    "    userSet=set([d[0] for d in train_set])\n",
    "    \n",
    "    # calculate average number of recipes made in the train_set\n",
    "    averageNum=len(train_set)/len(userSet)\n",
    "\n",
    "    # calculate most popular set in train_set\n",
    "    recipeCount = defaultdict(int)\n",
    "    totalCooked = 0\n",
    "    for d in train_set:\n",
    "        recipeCount[d[1]] += 1\n",
    "        totalCooked += 1\n",
    "\n",
    "    mostPopular = [(recipeCount[x], x) for x in recipeCount]\n",
    "    mostPopular.sort()\n",
    "    mostPopular.reverse()\n",
    "\n",
    "    return1 = set()\n",
    "    count = 0\n",
    "    for ic, i in mostPopular:\n",
    "        count += ic\n",
    "        return1.add(i)\n",
    "        if count > totalCooked*pt: break\n",
    "\n",
    "    predictions = open(\"predictions_Made.txt\", 'w')\n",
    "    for l in open(\"stub_Made.txt\"):\n",
    "        if l.startswith(\"user_id\"):\n",
    "            predictions.write(l)\n",
    "            continue\n",
    "        user,item = l.strip().split('-')\n",
    "        predict=0\n",
    "        \n",
    "        # if we have not met this user before, just recommend the most popular\n",
    "        if user not in userSet:\n",
    "            if item in return1:\n",
    "                predict=1\n",
    "        else:\n",
    "            # if we have not met this recipe before, if the user made many recipes before, then recommend\n",
    "            if item not in itemSet:\n",
    "                if len(itemsPerUser[user])>4*averageNum/3:\n",
    "                    predict=1\n",
    "            else:\n",
    "                if item in return1:\n",
    "                    predict=1\n",
    "                else:\n",
    "                    maxSim=0\n",
    "                    for d in itemsPerUser[user]:\n",
    "                        sim=Jaccard(usersPerItem[d],usersPerItem[item])\n",
    "                        maxSim=max(maxSim,sim)\n",
    "                    if maxSim>jt:\n",
    "                        predict=1\n",
    "        if predict==1:\n",
    "            predictions.write(user + '-' + item + \",1\\n\")\n",
    "        else:\n",
    "            predictions.write(user + '-' + item + \",0\\n\")\n",
    "    predictions.close()\n",
    "    print(\"predicting finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set=build_train_set(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting....\n",
      "predicting finished!\n"
     ]
    }
   ],
   "source": [
    "jaccardPopularityModel(train_set,0.001,0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bitc282c26bf4d14ab391e9a3806fefddf8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
